{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYu90W/id408MvN3+DC8rQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rxUO7ClbglT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "dci-84AGbrAW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJRjH6kBbrZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "73grnqA8br5a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0jXp-SIEbsOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Project Setup & Obtaining Dataset"
      ],
      "metadata": {
        "id": "f0k_ALtzjt0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if GPU is available\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "print(\"TensorFlow GPU available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"PyTorch GPU available:\", torch.cuda.is_available())\n",
        "\n",
        "# If using PyTorch, print GPU name\n",
        "if torch.cuda.is_available():\n",
        "    print(\"PyTorch GPU name:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "RAyBe-2WdB76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# install and update Hugging Face Transformers, Datasets, Accelerate, Evaluate\n",
        "# Also ensure fsspec and huggingface_hub are up-to-date to resolve common loading issues\n",
        "!pip install -U transformers datasets accelerate evaluate huggingface_hub fsspec sentencepiece -q"
      ],
      "metadata": {
        "id": "Ib9VUaw0dDpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load the ADE-Corpus-V2 classification dataset\n",
        "# this dataset contains sentences labeled as 0 (not ADE) or 1 (ADE)\n",
        "dataset = load_dataset(\"SetFit/ade_corpus_v2_classification\")\n",
        "\n",
        "print(\"\\nDataset loaded successfully!\")\n",
        "print(dataset)\n",
        "print(\"\\nKeys in the dataset object:\", dataset.keys())"
      ],
      "metadata": {
        "id": "H_sTj28MdLqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the training split\n",
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']\n",
        "\n",
        "print(\"\\n--- Training Dataset Sample ---\")\n",
        "print(train_dataset[0]) # Print the first example\n",
        "print(train_dataset[1]) # Print the second example\n",
        "\n",
        "print(\"\\n--- Test Dataset Sample ---\")\n",
        "print(test_dataset[0]) # Print the first example\n",
        "\n",
        "print(\"\\nFeatures (columns) available:\", train_dataset.column_names)\n",
        "print(\"Label mapping (if available):\", train_dataset.features['label'])"
      ],
      "metadata": {
        "id": "DkPteJ8odM_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Exploratory Data Analysis & Initial Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "IVxRVJOXdOnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert Hugging Face Datasets to Pandas DataFrames for easier EDA\n",
        "# initial exploration,\n",
        "train_df = dataset['train'].to_pandas()\n",
        "test_df = dataset['test'].to_pandas()\n",
        "\n",
        "print(f\"Train dataset size: {len(train_df)} rows\")\n",
        "print(f\"Test dataset size: {len(test_df)} rows\")\n",
        "\n",
        "print(\"\\n--- Training Data Class Distribution ---\")\n",
        "train_class_counts = train_df['label_text'].value_counts()\n",
        "print(train_class_counts)\n",
        "\n",
        "print(\"\\n--- Test Data Class Distribution ---\")\n",
        "test_class_counts = test_df['label_text'].value_counts()\n",
        "print(test_class_counts)\n",
        "\n",
        "# Visualize class distribution for training set\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.barplot(x=train_class_counts.index, y=train_class_counts.values, palette=\"viridis\")\n",
        "plt.title('Training Data Class Distribution (ADE vs. Non-ADE)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n",
        "\n",
        "# Visualize class distribution for test set\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.barplot(x=test_class_counts.index, y=test_class_counts.values, palette=\"plasma\")\n",
        "plt.title('Test Data Class Distribution (ADE vs. Non-ADE)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BDcDZfZodO9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate sentence lengths\n",
        "train_df['text_length'] = train_df['text'].apply(len)\n",
        "test_df['text_length'] = test_df['text'].apply(len)\n",
        "\n",
        "print(\"\\n--- Training Data Sentence Length Statistics (Characters) ---\")\n",
        "print(train_df['text_length'].describe())\n",
        "\n",
        "print(\"\\n--- Test Data Sentence Length Statistics (Characters) ---\")\n",
        "print(test_df['text_length'].describe())\n",
        "\n",
        "# Visualize sentence length distribution for training set\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train_df['text_length'], bins=50, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Sentence Lengths in Training Data')\n",
        "plt.xlabel('Sentence Length (Characters)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "# Visualize sentence length distribution for test set\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(test_df['text_length'], bins=50, kde=True, color='lightcoral')\n",
        "plt.title('Distribution of Sentence Lengths in Test Data')\n",
        "plt.xlabel('Sentence Length (Characters)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_OLtHFj-juGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Applies basic text cleaning: lowercasing, removing extra whitespace,\n",
        "    and removing non-alphanumeric characters (keeping spaces).\n",
        "    \"\"\"\n",
        "    text = text.lower() # Convert to lowercase\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove special characters, keep letters, numbers, spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Replace multiple spaces with single space and strip leading/trailing\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to the 'text' column in both train and test dataframes\n",
        "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
        "test_df['cleaned_text'] = test_df['text'].apply(clean_text)\n",
        "\n",
        "print(\"\\n--- Original vs. Cleaned Text Examples (Training Data) ---\")\n",
        "for i in range(5):\n",
        "    print(f\"Original: {train_df['text'].iloc[i]}\")\n",
        "    print(f\"Cleaned:  {train_df['cleaned_text'].iloc[i]}\\n\")\n",
        "\n",
        "# Store the dataframes back into the dataset object, or simply use train_df/test_df for next phase\n",
        "# For simplicity, keep working with train_df and test_df for now,\n",
        "# and convert back to Hugging Face Dataset format when needed\n",
        "\n",
        "# to update the original 'dataset' object:\n",
        "# from datasets import Dataset\n",
        "# dataset['train'] = Dataset.from_pandas(train_df)\n",
        "# dataset['test'] = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "id": "M8KP0rG8l0UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Baseline Model Development (ML & Feature Engineering)"
      ],
      "metadata": {
        "id": "iqhsD-6lst3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer - counts the occurrences of each word\n",
        "# max_features limits the number of unique words (vocabulary size) to consider,\n",
        "# which can help manage memory and focus on most frequent words.\n",
        "# min_df ignores words that appear in too few documents (e.g., typos, very rare words)\n",
        "# max_df ignores words that appear in too many documents (e.g., common words that aren't stop words)\n",
        "count_vectorizer = CountVectorizer(max_features=5000, min_df=5, max_df=0.9)\n",
        "\n",
        "# fit the vectorizer on the training data's cleaned text and transform both train and test data\n",
        "X_train_bow = count_vectorizer.fit_transform(train_df['cleaned_text'])\n",
        "X_test_bow = count_vectorizer.transform(test_df['cleaned_text'])\n",
        "\n",
        "# get labels (target variable)\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']\n",
        "\n",
        "print(f\"Shape of X_train_bow: {X_train_bow.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_bow.shape}\")\n",
        "print(f\"Vocabulary size: {len(count_vectorizer.vocabulary_)}\")"
      ],
      "metadata": {
        "id": "o1M5DRW5s2Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model, with CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "# max_iter increased to ensure convergence for larger datasets\n",
        "# solver='liblinear' good for smaller datasets and L1/L2 regularization\n",
        "# class_weight='balanced' CRUCIAL here because of our class imbalance.\n",
        "# It automatically adjusts weights inversely proportional to class frequencies.\n",
        "log_reg_model_bow = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42, class_weight='balanced')\n",
        "\n",
        "# Train the model\n",
        "log_reg_model_bow.fit(X_train_bow, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bow = log_reg_model_bow.predict(X_test_bow)\n",
        "\n",
        "print(\"\\n--- Logistic Regression (Bag-of-Words) Performance ---\")\n",
        "\n",
        "# Classification Report\n",
        "# This provides Precision, Recall, F1-score, and Support for each class.\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_bow, target_names=['Not-Related', 'Related']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_bow = confusion_matrix(y_test, y_pred_bow, labels=log_reg_model_bow.classes_)\n",
        "disp_bow = ConfusionMatrixDisplay(confusion_matrix=cm_bow, display_labels=['Not-Related', 'Related'])\n",
        "disp_bow.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix (Bag-of-Words)')\n",
        "plt.show()\n",
        "\n",
        "# raw confusion matrix\n",
        "print(\"\\nRaw Confusion Matrix:\\n\", cm_bow)"
      ],
      "metadata": {
        "id": "eAjFSknWwYnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TfidfVectorizer - Term Frequency-Inverse Document Frequency is\n",
        "# another common technique. It not only counts word occurrences but also gives\n",
        "# more weight to words that are rare across the entire corpus but frequent in a\n",
        "# specific document, it helps highlight words that are more distinctive.\n",
        "# Same parameters as CountVectorizer for consistency\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, min_df=5, max_df=0.9)\n",
        "\n",
        "# Fit & transform training data, transform test data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_text'])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['cleaned_text'])\n",
        "\n",
        "print(f\"Shape of X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_tfidf: {X_test_tfidf.shape}\")"
      ],
      "metadata": {
        "id": "0sMlwZSRyMeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model, using TF-IDF features.\n",
        "\n",
        "# Initialize Logistic Regression model with class_weight='balanced'\n",
        "log_reg_model_tfidf = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42, class_weight='balanced')\n",
        "\n",
        "# Train the model\n",
        "log_reg_model_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_tfidf = log_reg_model_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\n--- Logistic Regression (TF-IDF) Performance ---\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_tfidf, target_names=['Not-Related', 'Related']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_tfidf = confusion_matrix(y_test, y_pred_tfidf, labels=log_reg_model_tfidf.classes_)\n",
        "disp_tfidf = ConfusionMatrixDisplay(confusion_matrix=cm_tfidf, display_labels=['Not-Related', 'Related'])\n",
        "disp_tfidf.plot(cmap=plt.cm.Greens)\n",
        "plt.title('Confusion Matrix (TF-IDF)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nRaw Confusion Matrix:\\n\", cm_tfidf)"
      ],
      "metadata": {
        "id": "DkoJQVDby7rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HBDoYGi0Tt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}